{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreggRodgers02/Colab_notebooks/blob/main/Langchain_Lesson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom OpenAI Chatbot"
      ],
      "metadata": {
        "id": "fdYL6mrtK3Fi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V80orTYKI7fm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "p8RAb0cjJyP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIVG7EERJdx1",
        "outputId": "8c3c2d6c-e627-4527-a08c-233042bdc949"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "n6sq5T6dJqL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI()"
      ],
      "metadata": {
        "id": "7zLZMSh3J5_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(model=\"gpt-4o-mini\", messages=[\n",
        "                                                                           {'role': 'user',\n",
        "                                                                            'content': '''\n",
        "                                                                            Can you explain briefly what a black hole is?\n",
        "                                                                            '''}], max_tokens=250, temperature=0.3, seed=365, stream=True\n",
        "                                            )"
      ],
      "metadata": {
        "id": "e9zcJTdXKCJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion"
      ],
      "metadata": {
        "id": "7FElJsIpNA0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in completion:\n",
        "  print(i.choices[0].delta.content, end = \"\")"
      ],
      "metadata": {
        "id": "L0QmCj6KNC14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kqAtaKyxN4HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tweet Classifier HW"
      ],
      "metadata": {
        "id": "VGO64qeIOL-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            'content': '''\n",
        "            You are a tweet classifier, the user will give you a tween and your job is to classify the input between three categories:\n",
        "            1. Positive\n",
        "            2. Negative\n",
        "            3. Neutral\n",
        "            '''\n",
        "        },\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': 'This product is the worst!',\n",
        "            'role': 'assistant',\n",
        "            'content': 'Negative',\n",
        "            'role': 'user',\n",
        "            'content': 'I love this product!',\n",
        "            'role': 'assistant',\n",
        "            'content': 'Positive',\n",
        "            'role': 'user',\n",
        "            'content': 'The sale starts on Tuesday.',\n",
        "            'role': 'assistant',\n",
        "            'content': 'Neutral',\n",
        "            'role': 'user',\n",
        "            'content': 'I heard that the product is releasing within the United States.'\n",
        "        }\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "8Li8PXvBOOxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "d_q45_O-PrV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain Few-Shot Prompting"
      ],
      "metadata": {
        "id": "tK5AXtJMGUff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatMessagePromptTemplate"
      ],
      "metadata": {
        "id": "qrq_X-V_QFgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    temperature=0.4,\n",
        "    max_tokens=100,\n",
        "    model_kwargs={\n",
        "        \"seed\": 365\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "aXOY4K1qGhgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.invoke(''' I've recently adopted a dog. Could you suggest some dog names? ''')"
      ],
      "metadata": {
        "id": "YNIXtPYtHa40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "id": "frO_w6T0HrDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AI Message is use in Few-Shot Prompting, were we give the model a set of example responses to learn from."
      ],
      "metadata": {
        "id": "tfWzxSrCT-AJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message_h_dog = HumanMessage(content=\"I've recently adopted a dog. Could you suggest some dog names?\")\n",
        "\n",
        "message_h_cat = HumanMessage(content=\"I've recently adopted a cat. Could you suggest some cat names?\")"
      ],
      "metadata": {
        "id": "C_vgJXuUHtxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_ai_dog = AIMessage(content='''Oh, sure, because naming a dog is the most important decision you'll ever make. How about \"Bark Twain\" for a literary twist? Or maybe \"Sir Waggington\" if you want to feel fancy? If you’re feeling basic, “Buddy” works too. Just don’t\n",
        " blame me when your dog doesn’t live up to the name. Good luck!''')\n",
        "\n",
        "message_ai_cat = AIMessage(content='''Oh, sure, because naming a cat is the most important decision you’ll ever make. How about these gems:\n",
        "\n",
        "1. Whisker McFluffface\n",
        "2. Sir Purrs-a-lot\n",
        "3. Catrick Swayze\n",
        "4. Furrball McGee\n",
        "5. Chairman Meow\n",
        "\n",
        "Or you could just go with “Cat” and save yourself the trouble. Good luck!''')"
      ],
      "metadata": {
        "id": "C0OH4gF0UwAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jeNEUP7HVQz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_h_fish = HumanMessage(content=\"I've recently adopted a fish. Could you suggest some fish names?\")"
      ],
      "metadata": {
        "id": "tnLirTytWPPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_s = SystemMessage(content='''You are marv, a chat bot reluctantly\n",
        "answers questions with sarcastic responses''')"
      ],
      "metadata": {
        "id": "smjcRg73SlSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L7gxDa4FTy6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#response = chat.invoke([message_h_cat, message_s])"
      ],
      "metadata": {
        "id": "_advwxZ7UYbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.invoke([message_s, message_h_dog, message_ai_dog,message_h_cat, message_ai_cat, message_h_fish])"
      ],
      "metadata": {
        "id": "oOuhW8suRjmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "id": "5BtktmocSZ1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r4ioSLkyVhkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting Template"
      ],
      "metadata": {
        "id": "Fjzs_eHVjpDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate, FewShotChatMessagePromptTemplate, ChatPromptTemplate"
      ],
      "metadata": {
        "id": "ReZq7PsDkZ9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEMPLATE = '''\n",
        "System:\n",
        "{description}\n",
        "\n",
        "Human:\n",
        "I've recently adopted a {pet}.\n",
        "Could you suggest some {pet} names?\n",
        "'''"
      ],
      "metadata": {
        "id": "8EnhF_swj5oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate.from_template(template=TEMPLATE)"
      ],
      "metadata": {
        "id": "Ugui3-gVkc8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template"
      ],
      "metadata": {
        "id": "hpuNtWgxklfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_value = prompt_template.invoke({\n",
        "    'description':\"You are marv, a chat bot reluctantly answers questions with sarcastic responses\",\n",
        "    'pet':\"dog\"\n",
        "    })"
      ],
      "metadata": {
        "id": "CPJxBCXEknGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt_value.text)"
      ],
      "metadata": {
        "id": "D6zewfOtlI5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uLJIss4glLDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UylrtONqlpa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEMPLATE_S = '{description}'\n",
        "TEMPLATE_H = '''\n",
        "I've recently adopted a {pet}.\n",
        "Could you suggest some {pet} names?\n",
        "'''\n",
        "\n",
        "message_template_s = SystemMessagePromptTemplate.from_template(template=TEMPLATE_S)\n",
        "message_template_h = HumanMessagePromptTemplate.from_template(template=TEMPLATE_H)"
      ],
      "metadata": {
        "id": "OiLATf1QlpPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_template_s"
      ],
      "metadata": {
        "id": "FbvgoGqwm64t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_template_h"
      ],
      "metadata": {
        "id": "SB2MsOpTm9Ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template = ChatPromptTemplate.from_messages([message_template_s, message_template_h])"
      ],
      "metadata": {
        "id": "9pwTRmmpnDFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template"
      ],
      "metadata": {
        "id": "-KMs52H2nbGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_value = chat_template.invoke({\n",
        "    'description':\"You are marv, a chat bot reluctantly answers questions with sarcastic responses\",\n",
        "    'pet':\"dog\"\n",
        "})"
      ],
      "metadata": {
        "id": "dss00thqnkQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_value"
      ],
      "metadata": {
        "id": "Yl37E1vLnnwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.invoke(chat_value)"
      ],
      "metadata": {
        "id": "Wvk8bVgLnx05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.content"
      ],
      "metadata": {
        "id": "XvZFG7Vxn84d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rcpxPY8on-vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cleaner Few Shot Prompting"
      ],
      "metadata": {
        "id": "KHO0BH4cooDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEMPLATE_H = '''\n",
        "I've recently adopted a {pet}.\n",
        "Could you suggest some {pet} names?\n",
        "'''\n",
        "TEMPLATE_AI = '''{response}'''\n",
        "\n",
        "message_template_h = HumanMessagePromptTemplate.from_template(template=TEMPLATE_H)\n",
        "message_template_ai = AIMessagePromptTemplate.from_template(template=TEMPLATE_AI)"
      ],
      "metadata": {
        "id": "cgQVaDa6o8q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_template = ChatPromptTemplate.from_messages([message_template_h, message_template_ai])"
      ],
      "metadata": {
        "id": "PWIsNDJ_pg2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {'pet': 'dog',\n",
        "             'response':'''Oh, sure, because naming a dog is the most important decision you'll ever make. How about \"Bark Twain\" for a literary twist? Or maybe \"Sir Waggington\" if you want to feel fancy? If you’re feeling basic, “Buddy” works too. Just don’t\n",
        " blame me when your dog doesn’t live up to the name. Good luck!'''},\n",
        "\n",
        "  {'pet': 'cat',\n",
        "   'response':'''Oh, sure, because naming a cat is the most important decision you’ll ever make. How about these gems:\n",
        "\n",
        "1. Whisker McFluffface\n",
        "2. Sir Purrs-a-lot\n",
        "3. Catrick Swayze\n",
        "4. Furrball McGee\n",
        "5. Chairman Meow\n",
        "\n",
        "Or you could just go with “Cat” and save yourself the trouble. Good luck!'''}\n",
        "    ]"
      ],
      "metadata": {
        "id": "b5bQqnE4pmWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = FewShotChatMessagePromptTemplate(examples=examples,\n",
        "                                                   example_prompt=example_template,\n",
        "                                                   input_variables=['pet'])"
      ],
      "metadata": {
        "id": "Q4rPPCHAqoIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template = ChatPromptTemplate.from_messages([few_shot_prompt, message_template_h])"
      ],
      "metadata": {
        "id": "pl1oiTjgq_jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3i6SJa2xrZSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_value = chat_template.invoke({\n",
        "    'pet': 'rabbit'\n",
        "})"
      ],
      "metadata": {
        "id": "cFNEYlnlrbXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in chat_value.messages:\n",
        "  print(f\"{i.type}: {i.content} \\n\")"
      ],
      "metadata": {
        "id": "hMiN49Ukrk1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.invoke(chat_value)"
      ],
      "metadata": {
        "id": "Zyt5LVNYrmNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.content"
      ],
      "metadata": {
        "id": "Wd7h2uDbsEhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output Parser"
      ],
      "metadata": {
        "id": "Uis1jpZ6v8oL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The string output parser  converts an output to a string object"
      ],
      "metadata": {
        "id": "qk38XyX9wRlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "hJegg1o1sGUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_h = HumanMessage(\"Can you give me an interesting fact I probably didn't know about?\")"
      ],
      "metadata": {
        "id": "3r_YhyXJwZNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.invoke([message_h])"
      ],
      "metadata": {
        "id": "7FOabE2cwo78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "AxAXoc31wrsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str_output_parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "RrYBYLPZwuS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_parsed = str_output_parser.invoke(response)\n",
        "response_parsed"
      ],
      "metadata": {
        "id": "MvwmMVbRwz6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comma Parser returns a list"
      ],
      "metadata": {
        "id": "zhvDcslzSyaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import CommaSeparatedListOutputParser"
      ],
      "metadata": {
        "id": "_v0xm4b0w6tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    temperature=0.4,\n",
        "    max_tokens=100,\n",
        "    model_kwargs={\n",
        "        \"seed\": 365\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "bNwwD-MoxRgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c1f2541-60a5-4c13-c5ea-b1d1c85aa1f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3473: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can insert the instructions of the parser directly within the human message"
      ],
      "metadata": {
        "id": "29NTyRiYVMWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message_h = HumanMessage(content=f'''Ive recently adopted a dog. Could you suggest some dog names?\n",
        "\n",
        "\n",
        "{CommaSeparatedListOutputParser().get_format_instructions()}\n",
        "\n",
        "\n",
        "''')"
      ],
      "metadata": {
        "id": "VLKO2TzmxSG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(message_h.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNkvag8HUtuU",
        "outputId": "a4f66eb3-a2fb-42d4-e007-d64147153146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ive recently adopted a dog. Could you suggest some dog names?\n",
            "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reponse = chat.invoke([message_h])"
      ],
      "metadata": {
        "id": "18X0KxqmTcn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reponse.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkM6zoXdTyc-",
        "outputId": "ba7155ec-e353-4e72-b79e-77729d6fdfb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max, Bella, Charlie, Luna, Cooper, Daisy, Rocky, Sadie, Buddy, Molly, Duke, Zoe, Teddy, Ruby, Oliver, Chloe, Finn, Lily, Bear, Mia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_output_parser = CommaSeparatedListOutputParser()"
      ],
      "metadata": {
        "id": "qoMdO5ZZT2g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_parsed = list_output_parser.invoke(reponse)"
      ],
      "metadata": {
        "id": "7dvIN8zHUCI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_parsed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjiHcvO4UG7V",
        "outputId": "8e93bc47-04d5-405e-b06f-e7512300f9d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Max',\n",
              " 'Bella',\n",
              " 'Charlie',\n",
              " 'Luna',\n",
              " 'Cooper',\n",
              " 'Daisy',\n",
              " 'Rocky',\n",
              " 'Sadie',\n",
              " 'Buddy',\n",
              " 'Molly',\n",
              " 'Duke',\n",
              " 'Zoe',\n",
              " 'Teddy',\n",
              " 'Ruby',\n",
              " 'Oliver',\n",
              " 'Chloe',\n",
              " 'Finn',\n",
              " 'Lily',\n",
              " 'Bear',\n",
              " 'Mia']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_output_parser.get_format_instructions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "LrmWiwJDUIm4",
        "outputId": "1a42046f-84e9-4a21-ac16-a0dd08b9bb62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OeXx1sO5UYbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datetime parser"
      ],
      "metadata": {
        "id": "pSzBBDQMVHAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain_core.output_parsers as op\n",
        "dir(op)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ_rvHfKVT25",
        "outputId": "600fe62e-a737-417c-b672-f8fcc6806744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BaseCumulativeTransformOutputParser',\n",
              " 'BaseGenerationOutputParser',\n",
              " 'BaseLLMOutputParser',\n",
              " 'BaseOutputParser',\n",
              " 'BaseTransformOutputParser',\n",
              " 'CommaSeparatedListOutputParser',\n",
              " 'JsonOutputKeyToolsParser',\n",
              " 'JsonOutputParser',\n",
              " 'JsonOutputToolsParser',\n",
              " 'ListOutputParser',\n",
              " 'MarkdownListOutputParser',\n",
              " 'NumberedListOutputParser',\n",
              " 'PydanticOutputParser',\n",
              " 'PydanticToolsParser',\n",
              " 'SimpleJsonOutputParser',\n",
              " 'StrOutputParser',\n",
              " 'XMLOutputParser']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser, SimpleJsonOutputParser"
      ],
      "metadata": {
        "id": "9GFM7-jvVdtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(SimpleJsonOutputParser().get_format_instructions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vPCA0y4W8BZ",
        "outputId": "aae08e3b-0cc9-4695-86cb-977566a695da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Return a JSON object.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZgQUJS8CXFSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Piping a Prompt, Model, and an Output Parser**"
      ],
      "metadata": {
        "id": "XTiehOMgbGqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import CommaSeparatedListOutputParser"
      ],
      "metadata": {
        "id": "T25OL5qzbLFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_instructions = CommaSeparatedListOutputParser().get_format_instructions()"
      ],
      "metadata": {
        "id": "AiLhSyGEbi8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_instructions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tK_DPBkpebKL",
        "outputId": "a3e60629-b248-4e4d-fb65-bb2b5ac2fc03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template = ChatPromptTemplate.from_messages([\n",
        "    ('human',\n",
        "     'I have recently adopted a {pet}. Could you suggest somthreee {pet} names? \\n' + list_instructions)\n",
        "])"
      ],
      "metadata": {
        "id": "_cyaS18qedKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_template.messages[0].prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M41TbEPkfCnT",
        "outputId": "84229c0a-aaa5-48eb-8584-e7c2c9b8c791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have recently adopted a {pet}. Could you suggest somthreee {pet} names? \n",
            "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    model_kwargs={\"seed\": 365}\n",
        ")"
      ],
      "metadata": {
        "id": "n402zvLyfESh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_output_parser = CommaSeparatedListOutputParser()"
      ],
      "metadata": {
        "id": "Z6SG-U4Xfy7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template_results = chat_template.invoke({'pet': 'dog'})"
      ],
      "metadata": {
        "id": "9n5wc9Fqf8HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_results = chat.invoke(chat_template_results)"
      ],
      "metadata": {
        "id": "aI5s8P7OgDoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_output_parser.invoke(chat_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZTS757fgN41",
        "outputId": "227c130b-5ecc-4947-afdf-b97453a2def9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Buddy', 'Bella', 'Max']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "    chat_template\n",
        "    | chat\n",
        "    | list_output_parser\n",
        ")\n",
        "\n",
        "chain.invoke({\n",
        "    'pet': 'cat'\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO06hefDhtT5",
        "outputId": "291b130e-6e1c-4371-a7f1-a7c8fd150961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Whiskers', 'Luna', 'Oliver']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Batching**"
      ],
      "metadata": {
        "id": "dRtF3_5winJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "exwyehf3h0pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template = ChatPromptTemplate.from_messages([\n",
        "    ('human',\n",
        "     'I have recently adopted a {pet} which is a {breed}. Could you suggest several training tips?')\n",
        "])"
      ],
      "metadata": {
        "id": "Mr5v8dtJi47G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    model_kwargs={\"seed\": 365}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VftCjBnjAQx",
        "outputId": "6e99de47-98fe-4c7f-9481-5f3fef742d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3473: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "    chat_template\n",
        "    | chat\n",
        ")"
      ],
      "metadata": {
        "id": "ycPB1KqFjD1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\n",
        "    'pet': 'dog',\n",
        "    'breed': 'golden retriever'\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYd2OIG5jI9g",
        "outputId": "3ba87783-49df-4ead-8474-e4eae5389707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Congratulations on your new golden retriever! They are known for their friendly and intelligent nature, making them great companions. Here are several training tips to help you get started:\\n\\n1. **Start with Basic Commands**: Teach essential commands like \"sit,\" \"stay,\" \"come,\" \"down,\" and \"leave it.\" Use positive reinforcement, such as treats and praise, to encourage good behavior.\\n\\n2. **Consistency is Key**: Use the same commands and cues consistently. This helps your dog understand', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 27, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_454234172d', 'id': 'chatcmpl-D6mbuowUB1K0EVo2wneEQ2gn3S0G6', 'service_tier': 'default', 'finish_reason': 'length', 'logprobs': None}, id='lc_run--019c3a92-609c-73e3-8d22-cae4bd5e8472-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 27, 'output_tokens': 100, 'total_tokens': 127, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The batch() method runs invoke() in parallel"
      ],
      "metadata": {
        "id": "I7Lh9U_sj2wT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "chain.batch([\n",
        "    {\n",
        "        'pet': 'dog',\n",
        "        'breed': 'shepard'\n",
        "    },\n",
        "    {\n",
        "        'pet': 'dragon',\n",
        "        'breed': 'night fury'\n",
        "    }\n",
        "    ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygnYjZ-qjr2E",
        "outputId": "ec918f6c-34d3-47cc-dbdc-ba774ea41931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 26 ms, sys: 0 ns, total: 26 ms\n",
            "Wall time: 1.25 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='Congratulations on your new shepherd! Here are several training tips to help you and your dog build a strong bond and ensure good behavior:\\n\\n1. **Start with Basic Commands**: Teach essential commands like \"sit,\" \"stay,\" \"come,\" \"down,\" and \"leave it.\" Use positive reinforcement, such as treats and praise, to encourage your dog.\\n\\n2. **Consistency is Key**: Use the same commands and gestures consistently. This helps your dog understand what you expect from them.\\n\\n3.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 26, 'total_tokens': 126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_454234172d', 'id': 'chatcmpl-D6mdgkexMHOdQgr6wXjjiE5qXApVx', 'service_tier': 'default', 'finish_reason': 'length', 'logprobs': None}, id='lc_run--019c3a94-100d-7273-bbbd-56cb3a40e8ca-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 26, 'output_tokens': 100, 'total_tokens': 126, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              " AIMessage(content='Training a Night Fury, like Toothless from \"How to Train Your Dragon,\" can be a fun and rewarding experience! Here are several tips to help you train your new dragon:\\n\\n1. **Build Trust**: Establish a bond with your Night Fury by spending time together. Offer treats (like fish or other favorite foods) and engage in gentle play to build trust.\\n\\n2. **Positive Reinforcement**: Use positive reinforcement techniques. Reward your dragon with treats or praise when it follows commands or exhibits', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 26, 'total_tokens': 126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_454234172d', 'id': 'chatcmpl-D6mdgsfaK0BDiN6xeRuHbPrXjeNtx', 'service_tier': 'default', 'finish_reason': 'length', 'logprobs': None}, id='lc_run--019c3a94-100f-7a22-8d7c-cfd0531e2654-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 26, 'output_tokens': 100, 'total_tokens': 126, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Streaming**"
      ],
      "metadata": {
        "id": "tqzPtRn-lYU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    model_kwargs={\"seed\": 365}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxgxgjebmNAk",
        "outputId": "bb30b85a-d2fc-4b57-dd6e-f45d499278b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3473: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "    chat_template\n",
        "    | chat\n",
        ")"
      ],
      "metadata": {
        "id": "YvyZzAygm7Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.stream({\n",
        "    'pet': 'dog',\n",
        "    'breed': 'Boxer'\n",
        "})"
      ],
      "metadata": {
        "id": "fzx1c5PokWOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator Functions allow for defining functions that behave like iterators, allowing us to loop over there output"
      ],
      "metadata": {
        "id": "DaKBeDvMlvhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm8FCMHYlrj9",
        "outputId": "36450652-ef63-43b7-cd43-e4b89171f9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019c3a9e-0a7c-7d21-8140-0dbcb7b4e528', tool_calls=[], invalid_tool_calls=[], tool_call_chunks=[])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To access the elements in a generator one at atime, we set it as an argument to the built in python function called next"
      ],
      "metadata": {
        "id": "8lqXRmyimYCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in response:\n",
        "  print(i.content, end = \"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pQSRLH1mjEa",
        "outputId": "c045020f-4add-4594-ba8e-8f40af53d9aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Congratulations on adopting a Boxer! They are known for their playful and energetic nature, so training is essential for a well-behaved companion. Here are several training tips to help you get started:\n",
            "\n",
            "1. **Start with Basic Commands**: Teach basic commands like \"sit,\" \"stay,\" \"come,\" and \"down.\" Use positive reinforcement, such as treats and praise, to encourage good behavior.\n",
            "\n",
            "2. **Consistency is Key**: Be consistent with commands and rules. Use the same words and"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The end argument allow us to display the results horizontally"
      ],
      "metadata": {
        "id": "rt50rwN2nStV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B5E__oeAnYbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The Runnable and RunnableSequence Classes**"
      ],
      "metadata": {
        "id": "M2RiN22yq3XE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "kcmOxtQvq72a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template = ChatPromptTemplate.from_messages([\n",
        "    ('human',\n",
        "     'I have recently adopted a {pet} which is a {breed}. Could you suggest several training tips?')\n",
        "])"
      ],
      "metadata": {
        "id": "R4SkJR88q-zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    model_kwargs={\"seed\": 365}\n",
        ")"
      ],
      "metadata": {
        "id": "KP2vJH0YrCfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8c6803b-3464-4056-8044-a4a89185f18e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3473: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = chat_template | chat"
      ],
      "metadata": {
        "id": "lY0OPyd6rEjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(chat_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "5CYdjAALrHer",
        "outputId": "1ac85ea2-9d29-4b3d-b0dc-32f8793b15d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.prompts.chat.ChatPromptTemplate"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.prompts.chat.ChatPromptTemplate</b><br/>def __init__(messages: Sequence[MessageLikeRepresentation], *, template_format: PromptTemplateFormat=&#x27;f-string&#x27;, **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/langchain_core/prompts/chat.py</a>Prompt template for chat models.\n",
              "\n",
              "Use to create flexible templated prompts for chat models.\n",
              "\n",
              "!!! example\n",
              "\n",
              "    ```python\n",
              "    from langchain_core.prompts import ChatPromptTemplate\n",
              "\n",
              "    template = ChatPromptTemplate(\n",
              "        [\n",
              "            (&quot;system&quot;, &quot;You are a helpful AI bot. Your name is {name}.&quot;),\n",
              "            (&quot;human&quot;, &quot;Hello, how are you doing?&quot;),\n",
              "            (&quot;ai&quot;, &quot;I&#x27;m doing well, thanks!&quot;),\n",
              "            (&quot;human&quot;, &quot;{user_input}&quot;),\n",
              "        ]\n",
              "    )\n",
              "\n",
              "    prompt_value = template.invoke(\n",
              "        {\n",
              "            &quot;name&quot;: &quot;Bob&quot;,\n",
              "            &quot;user_input&quot;: &quot;What is your name?&quot;,\n",
              "        }\n",
              "    )\n",
              "    # Output:\n",
              "    # ChatPromptValue(\n",
              "    #    messages=[\n",
              "    #        SystemMessage(content=&#x27;You are a helpful AI bot. Your name is Bob.&#x27;),\n",
              "    #        HumanMessage(content=&#x27;Hello, how are you doing?&#x27;),\n",
              "    #        AIMessage(content=&quot;I&#x27;m doing well, thanks!&quot;),\n",
              "    #        HumanMessage(content=&#x27;What is your name?&#x27;)\n",
              "    #    ]\n",
              "    # )\n",
              "    ```\n",
              "\n",
              "!!! note &quot;Messages Placeholder&quot;\n",
              "\n",
              "    ```python\n",
              "    # In addition to Human/AI/Tool/Function messages,\n",
              "    # you can initialize the template with a MessagesPlaceholder\n",
              "    # either using the class directly or with the shorthand tuple syntax:\n",
              "\n",
              "    template = ChatPromptTemplate(\n",
              "        [\n",
              "            (&quot;system&quot;, &quot;You are a helpful AI bot.&quot;),\n",
              "            # Means the template will receive an optional list of messages under\n",
              "            # the &quot;conversation&quot; key\n",
              "            (&quot;placeholder&quot;, &quot;{conversation}&quot;),\n",
              "            # Equivalently:\n",
              "            # MessagesPlaceholder(variable_name=&quot;conversation&quot;, optional=True)\n",
              "        ]\n",
              "    )\n",
              "\n",
              "    prompt_value = template.invoke(\n",
              "        {\n",
              "            &quot;conversation&quot;: [\n",
              "                (&quot;human&quot;, &quot;Hi!&quot;),\n",
              "                (&quot;ai&quot;, &quot;How can I assist you today?&quot;),\n",
              "                (&quot;human&quot;, &quot;Can you make me an ice cream sundae?&quot;),\n",
              "                (&quot;ai&quot;, &quot;No.&quot;),\n",
              "            ]\n",
              "        }\n",
              "    )\n",
              "\n",
              "    # Output:\n",
              "    # ChatPromptValue(\n",
              "    #    messages=[\n",
              "    #        SystemMessage(content=&#x27;You are a helpful AI bot.&#x27;),\n",
              "    #        HumanMessage(content=&#x27;Hi!&#x27;),\n",
              "    #        AIMessage(content=&#x27;How can I assist you today?&#x27;),\n",
              "    #        HumanMessage(content=&#x27;Can you make me an ice cream sundae?&#x27;),\n",
              "    #        AIMessage(content=&#x27;No.&#x27;),\n",
              "    #    ]\n",
              "    # )\n",
              "    ```\n",
              "\n",
              "!!! note &quot;Single-variable template&quot;\n",
              "\n",
              "    If your prompt has only a single input variable (i.e., one instance of\n",
              "    `&#x27;{variable_nams}&#x27;`), and you invoke the template with a non-dict object, the\n",
              "    prompt template will inject the provided argument into that variable location.\n",
              "\n",
              "    ```python\n",
              "    from langchain_core.prompts import ChatPromptTemplate\n",
              "\n",
              "    template = ChatPromptTemplate(\n",
              "        [\n",
              "            (&quot;system&quot;, &quot;You are a helpful AI bot. Your name is Carl.&quot;),\n",
              "            (&quot;human&quot;, &quot;{user_input}&quot;),\n",
              "        ]\n",
              "    )\n",
              "\n",
              "    prompt_value = template.invoke(&quot;Hello, there!&quot;)\n",
              "    # Equivalent to\n",
              "    # prompt_value = template.invoke({&quot;user_input&quot;: &quot;Hello, there!&quot;})\n",
              "\n",
              "    # Output:\n",
              "    #  ChatPromptValue(\n",
              "    #     messages=[\n",
              "    #         SystemMessage(content=&#x27;You are a helpful AI bot. Your name is Carl.&#x27;),\n",
              "    #         HumanMessage(content=&#x27;Hello, there!&#x27;),\n",
              "    #     ]\n",
              "    # )\n",
              "    ```</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 789);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VDH5OkwCrOOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A runnable is a unit of work that can be invoked, batched, streamed, transformed and composed"
      ],
      "metadata": {
        "id": "oJdJ215-rmw3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z31qgG6Zrw6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Piping Chains and the RunnablePassthrough Class**"
      ],
      "metadata": {
        "id": "vcQBZDtjhEGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "-Ga_LFlbhMCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RunnablePassthrough().invoke('Hello')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1bwdKzKShU56",
        "outputId": "3152afe2-5482-42ae-b4cf-960e8fa7cfa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template_tools = ChatPromptTemplate.from_template(\n",
        "    '''\n",
        "    What are the five most important tools a {job_title} needs?\n",
        "    Answer only by listing the tools.\n",
        "    '''\n",
        ")\n",
        "\n",
        "chat_template_strategy = ChatPromptTemplate.from_template(\n",
        "    '''\n",
        "    Considering the tools provided, develop a strategy for effectively learning and mastering them:\n",
        "    {tools}\n",
        "    '''\n",
        ")"
      ],
      "metadata": {
        "id": "KAEu-YZShe4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template_tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjZz7lvJh9sw",
        "outputId": "5dacb26a-3992-4205-b1f2-3c7d4d46030d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['job_title'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['job_title'], input_types={}, partial_variables={}, template='\\n    What are the five most important tools a {job_title} needs?\\n    Answer only by listing the tools.\\n    '), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    model_kwargs={\"seed\": 365}\n",
        ")"
      ],
      "metadata": {
        "id": "KG31EeHKh_3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "qq0NoOgHiXR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_tools = (\n",
        "    chat_template_tools\n",
        "    | chat\n",
        "    | string_parser\n",
        "    | {'tools': RunnablePassthrough()}\n",
        ")\n",
        "\n",
        "chain_strategy = (\n",
        "    chat_template_strategy\n",
        "    | chat\n",
        "    | string_parser\n",
        ")"
      ],
      "metadata": {
        "id": "ko8UYEhzia9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools_results = chain_tools.invoke({'job_title': 'data scientist'})"
      ],
      "metadata": {
        "id": "SSlE_wIBirRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tools_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw1w2ObtkFrK",
        "outputId": "582f2737-f86c-46f2-b374-bbf704a872f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tools': '1. Python\\n2. R\\n3. SQL\\n4. Jupyter Notebook\\n5. TensorFlow/PyTorch'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain_strategy.invoke({\n",
        "    'tools': tools_results\n",
        "    }))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcivYpw_iyqY",
        "outputId": "4d898a76-7855-463b-99eb-feb2ba5f9dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To effectively learn and master the tools you've listed—Python, R, SQL, Jupyter Notebook, and TensorFlow/PyTorch—it's essential to develop a structured strategy that incorporates both theoretical understanding and practical application. Here’s a step-by-step approach:\n",
            "\n",
            "### 1. **Set Clear Goals**\n",
            "   - Define what you want to achieve with each tool. For example:\n",
            "     - Python: General programming and data analysis.\n",
            "     - R: Statistical analysis and data visualization.\n",
            "     - SQL: Database\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_combined = (\n",
        "    chain_tools\n",
        "    | chain_strategy\n",
        ")"
      ],
      "metadata": {
        "id": "s7G2GdxGjlBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_combined.invoke({'job_title': 'data scientist'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Z_Tn5-cJkbO5",
        "outputId": "52a287c5-6443-4a0b-bfe3-196e5c19a1fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"To effectively learn and master the tools you've listed—Python, R, SQL, Jupyter Notebook, and TensorFlow/PyTorch—it's essential to develop a structured strategy that incorporates both theoretical understanding and practical application. Here’s a step-by-step approach:\\n\\n### 1. **Set Clear Goals**\\n   - Define what you want to achieve with each tool. For example:\\n     - Python: General programming and data analysis.\\n     - R: Statistical analysis and data visualization.\\n     - SQL: Database\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Long_chain = (\n",
        "    chat_template_tools\n",
        "    | chat\n",
        "    | string_parser\n",
        "    | {'tools': RunnablePassthrough()}\n",
        "    | chat_template_strategy\n",
        "    | chat\n",
        "    | string_parser\n",
        ")"
      ],
      "metadata": {
        "id": "SfvpKpYxkdgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FwpH88zrk59t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Graphing Runnables**"
      ],
      "metadata": {
        "id": "iOo9RqMAlc55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install grandalf\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "zYgY9SE_lgP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template_tools = ChatPromptTemplate.from_template(\n",
        "    '''\n",
        "    What are the five most important tools a {job_title} needs?\n",
        "    Answer only by listing the tools.\n",
        "    '''\n",
        ")\n",
        "\n",
        "chat_template_strategy = ChatPromptTemplate.from_template(\n",
        "    '''\n",
        "    Considering the tools provided, develop a strategy for effectively learning and mastering them:\n",
        "    {tools}\n",
        "    '''\n",
        ")"
      ],
      "metadata": {
        "id": "5o4zUDzallku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    model_kwargs={\"seed\": 365}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC-Kw810lv9Q",
        "outputId": "2d819399-1077-4df2-bcaf-18150241c17d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3473: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string_parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "9hkoHPZElyO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_long = (\n",
        "    chat_template_tools\n",
        "    | chat\n",
        "    | string_parser\n",
        "    | {'tools': RunnablePassthrough()}\n",
        "    | chat_template_strategy\n",
        "    | chat\n",
        "    | string_parser\n",
        ")"
      ],
      "metadata": {
        "id": "wPuN55Vzl0mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_long.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iA8xfscl28u",
        "outputId": "bc2ae172-8526-4c5e-975d-4e858570b181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     +-------------+       \n",
            "     | PromptInput |       \n",
            "     +-------------+       \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "  +--------------------+   \n",
            "  | ChatPromptTemplate |   \n",
            "  +--------------------+   \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "      +------------+       \n",
            "      | ChatOpenAI |       \n",
            "      +------------+       \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "   +-----------------+     \n",
            "   | StrOutputParser |     \n",
            "   +-----------------+     \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "+-----------------------+  \n",
            "| StrOutputParserOutput |  \n",
            "+-----------------------+  \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "     +-------------+       \n",
            "     | Passthrough |       \n",
            "     +-------------+       \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "  +--------------------+   \n",
            "  | ChatPromptTemplate |   \n",
            "  +--------------------+   \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "      +------------+       \n",
            "      | ChatOpenAI |       \n",
            "      +------------+       \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "   +-----------------+     \n",
            "   | StrOutputParser |     \n",
            "   +-----------------+     \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "+-----------------------+  \n",
            "| StrOutputParserOutput |  \n",
            "+-----------------------+  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ifh2OQmPmGRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RunnableParallel**"
      ],
      "metadata": {
        "id": "YvRnh47a0cC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain_openai\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableParallel"
      ],
      "metadata": {
        "id": "XsKVABR70fc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template_books = ChatPromptTemplate.from_template(\n",
        "    '''\n",
        "    Suggest three of the best intermediate-level {programming language} books.\n",
        "    Answer only bu listing the books\n",
        "    '''\n",
        ")\n",
        "\n",
        "chat_template_project = ChatPromptTemplate.from_template(\n",
        "    '''\n",
        "    Suggest three interesting {programming language} projects suitable for intermediate-level programmers.\n",
        "    Answer only by listing the projects.\n",
        "    '''\n",
        ")\n",
        "\n",
        "chat_template_time = ChatPromptTemplate.from_template(\n",
        "    '''\n",
        "    I am an intermeidiate level programmer.\n",
        "\n",
        "    Consider the following literature:\n",
        "    {books}\n",
        "\n",
        "    Also, consider the following projects:\n",
        "    {projects}\n",
        "\n",
        "    Roughly how much time would it take me to complete the literature and the projects?\n",
        "\n",
        "    '''\n",
        ")"
      ],
      "metadata": {
        "id": "6yZPletC0wPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        "    max_tokens=500,\n",
        "    model_kwargs={\"seed\": 365}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs_YtYun1gW6",
        "outputId": "f41fc093-f9ad-4101-f469-b7cffc02de65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3473: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string_parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "r9BOHmDT1iYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_books = (\n",
        "    chat_template_books\n",
        "    | chat\n",
        "    | string_parser\n",
        ")\n",
        "\n",
        "chain_projects = (\n",
        "    chat_template_project\n",
        "    | chat\n",
        "    | string_parser\n",
        ")"
      ],
      "metadata": {
        "id": "I5elt4-112-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_parallel = RunnableParallel(\n",
        "    {'books': chain_books, 'projects': chain_projects}\n",
        ")"
      ],
      "metadata": {
        "id": "jt4Ju5ZY1_at"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_parallel.invoke({'programming language': 'python'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfzzi8Om2dZc",
        "outputId": "b70357ab-7b0b-4fe9-f6b6-9fb480691910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'books': '1. \"Fluent Python\" by Luciano Ramalho  \\n2. \"Effective Python: 90 Specific Ways to Write Better Python\" by Brett Slatkin  \\n3. \"Python Cookbook\" by David Beazley and Brian K. Jones  ',\n",
              " 'projects': '1. Personal Finance Tracker with Data Visualization  \\n2. Web Scraper with Automated Reporting  \\n3. Chatbot using Natural Language Processing'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_time_1 = (\n",
        "    RunnableParallel({'books': chain_books, 'projects': chain_projects})\n",
        "    | chat_template_time\n",
        "    | chat\n",
        "    | string_parser\n",
        ")\n",
        "\n",
        "\n",
        "#Best practice\n",
        "chain_time_2 = (\n",
        "     ({'books': chain_books,\n",
        "       'projects': chain_projects})\n",
        "    | chat_template_time\n",
        "    | chat\n",
        "    | string_parser\n",
        ")"
      ],
      "metadata": {
        "id": "6SbLKYzR20GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain_time_2.invoke({'programming language': 'python'}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycV1huue2f1c",
        "outputId": "fa4a34c0-3799-48e9-a424-ae6b4647f794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The time it takes to complete the literature and projects can vary significantly based on your current skill level, the depth of understanding you aim to achieve, and the complexity of the projects. However, I can provide a rough estimate for each component.\n",
            "\n",
            "### Literature\n",
            "\n",
            "1. **\"Fluent Python\" by Luciano Ramalho**  \n",
            "   - Estimated Time: 4-6 weeks  \n",
            "   - This book is comprehensive and covers advanced Python concepts. If you dedicate around 10-15 hours per week, you can expect to finish it in about a month.\n",
            "\n",
            "2. **\"Effective Python: 90 Specific Ways to Write Better Python\" by Brett Slatkin**  \n",
            "   - Estimated Time: 2-3 weeks  \n",
            "   - This book is more concise and can be read more quickly. Spending about 5-10 hours per week should allow you to complete it in a couple of weeks.\n",
            "\n",
            "3. **\"Python Cookbook\" by David Beazley and Brian K. Jones**  \n",
            "   - Estimated Time: 3-4 weeks  \n",
            "   - This book is practical and involves working through recipes. If you spend around 10 hours a week, you can finish it in about a month.\n",
            "\n",
            "### Total Literature Time: \n",
            "Approximately **9-13 weeks** (2-3 months) if you read them sequentially.\n",
            "\n",
            "### Projects\n",
            "\n",
            "1. **Personal Finance Tracker**  \n",
            "   - Estimated Time: 4-6 weeks  \n",
            "   - Depending on the features you want to implement (e.g., budgeting, expense tracking, reporting), this could take a month or more.\n",
            "\n",
            "2. **Web Scraper with Data Visualization**  \n",
            "   - Estimated Time: 3-5 weeks  \n",
            "   - The time will depend on the complexity of the website you are scraping and the visualization tools you choose to use.\n",
            "\n",
            "3. **Chatbot using Natural Language Processing**  \n",
            "   - Estimated Time: 4-8 weeks  \n",
            "   - Building a chatbot can be complex, especially if you want to implement advanced NLP features. This could take a month or more.\n",
            "\n",
            "### Total Project Time: \n",
            "Approximately **11-19 weeks** (3-5 months) if you work on them sequentially.\n",
            "\n",
            "### Overall Estimate\n",
            "Combining both literature and projects, you might be looking at a total of **20-32 weeks** (5-8 months) to complete everything, assuming you work on them sequentially and dedicate a reasonable amount of time each week.\n",
            "\n",
            "### Note\n",
            "- If you can work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t_CEiYQU2nmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Runnable Lambda**"
      ],
      "metadata": {
        "id": "57Fw5b_062s2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda"
      ],
      "metadata": {
        "id": "_KXSX1sg7rxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_sum = lambda x: sum(x)"
      ],
      "metadata": {
        "id": "op_CDqh_66IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_sum([1, 2, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnruZOMt7S46",
        "outputId": "7e4b2f8e-cf9a-4792-a0da-2de173ec54b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_square = lambda x: x**2"
      ],
      "metadata": {
        "id": "bAhNm-zK7WlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_square(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4VziEmA7fB2",
        "outputId": "661bc054-4ba0-4b5f-8904-41c9459da7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runnable_sum = RunnableLambda(lambda x: sum(x))\n",
        "runnable_square = RunnableLambda(lambda x: x**2)"
      ],
      "metadata": {
        "id": "bRjPl7X47idz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runnable_sum.invoke([1, 2, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzkRAurN73w2",
        "outputId": "9856d917-5470-4920-fbdd-fd27abe692c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runnable_square.invoke(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeZAYibW76X3",
        "outputId": "436c4336-fec1-47a0-c9b0-7a388608a8a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "    runnable_sum\n",
        "    | runnable_square\n",
        ")"
      ],
      "metadata": {
        "id": "lDhMBGja7_wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke([1, 2, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiZvMI3P8Ihu",
        "outputId": "caad5bc6-3882-458f-8d08-e115402e11fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uvWnFRyd8MEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **@chain Decorator**"
      ],
      "metadata": {
        "id": "vwYw6CuY8ec5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_core.runnables import chain"
      ],
      "metadata": {
        "id": "aLzA0Xr08gxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_sum(x):\n",
        "  return sum(x)\n",
        "\n",
        "def find_square(x):\n",
        "  return x**2"
      ],
      "metadata": {
        "id": "2NGoQQVk8oKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain1 = (\n",
        "    RunnableLambda(find_sum)\n",
        "    | RunnableLambda(find_square)\n",
        ")"
      ],
      "metadata": {
        "id": "Jp3dSe0n8v7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain1.invoke([1,2,5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrDV8q0O9KzM",
        "outputId": "705db721-3dd6-4546-e696-5dec431b1bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r1XmkUKs9OKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@chain\n",
        "def runnable_sum(x):\n",
        "  return sum(x)\n",
        "\n",
        "@chain\n",
        "def runnable_square(x):\n",
        "  return x**2"
      ],
      "metadata": {
        "id": "EH5skOaU9UYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(runnable_sum), type(runnable_square)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4Be87Qo9cgB",
        "outputId": "534b3acf-4357-4995-dcf2-8582739b1bc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(langchain_core.runnables.base.RunnableLambda,\n",
              " langchain_core.runnables.base.RunnableLambda)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain2 = (\n",
        "    runnable_sum\n",
        "    | runnable_square\n",
        ")"
      ],
      "metadata": {
        "id": "ZwSVCAmU9rj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain2.invoke([1,2,5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtnCigzC90ZB",
        "outputId": "ec767ab6-177c-4d06-e6d2-deba7943903c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mOSUzG319-Ek"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}